# Algoritmos de Ensemble para Detecci√≥n de Exoplanetas

## üß† Fundamentos de Ensemble Learning

### Concepto Fundamental
Los **algoritmos ensemble** combinan m√∫ltiples algoritmos de machine learning para obtener una predicci√≥n final mejorada. El principio b√°sico es que las predicciones incorrectas de un algoritmo pueden ser compensadas por predicciones correctas de otro, resultando en un rendimiento superior al de cualquier algoritmo individual.

### Arquitectura T√≠pica de Ensemble
```
Datos de Entrada
       ‚Üì
   Algoritmo 1 ‚Üí Predicci√≥n 1
   Algoritmo 2 ‚Üí Predicci√≥n 2    ‚Üí Esquema de Votaci√≥n ‚Üí Predicci√≥n Final
   Algoritmo N ‚Üí Predicci√≥n N
```

## üîÑ Estrategias para Diversidad en Ensemble

### 1. Manipulaci√≥n de Entrada (Input Manipulation)
- Cada algoritmo base se entrena con diferentes subconjuntos de datos
- **Bagging**: Bootstrap Aggregating
- **Random Subspace**: Selecci√≥n aleatoria de caracter√≠sticas

### 2. Manipulaci√≥n del Aprendizaje (Learning Manipulation)
- Modificaci√≥n del proceso de b√∫squeda de la soluci√≥n √≥ptima
- **Boosting**: Aprendizaje secuencial con re-pesado de errores
- Diferentes funciones de p√©rdida o criterios de optimizaci√≥n

### 3. Particionamiento (Partitioning)
- Divisi√≥n del dataset en subconjuntos especializados
- Cada algoritmo se especializa en una regi√≥n del espacio de caracter√≠sticas

### 4. Hibridaci√≥n (Hybridization)
- Combinaci√≥n de dos o m√°s estrategias anteriores
- Enfoques multi-nivel y jer√°rquicos

## üéØ Cinco Algoritmos Ensemble Evaluados

### 1. AdaBoost (Adaptive Boosting)

#### Principio de Funcionamiento
- **Tipo**: Boosting secuencial
- **M√©todo de Fusi√≥n**: Votaci√≥n ponderada
- **Dependencia**: Secuencial (algoritmos posteriores dependen de anteriores)
- **Entrenamiento**: Adaptativo con re-pesado de muestras

#### Caracter√≠sticas T√©cnicas
```python
# Hiperpar√°metros clave
n_estimators: N√∫mero de algoritmos base
learning_rate: Tasa de aprendizaje
algorithm: SAMME o SAMME.R
```

#### Rendimiento en Exoplanetas
- **Accuracy inicial**: 81.37%
- **Accuracy optimizada**: 82.52% (+1.15%)
- **Mejora**: Incremento significativo con m√°s estimadores
- **Fortalezas**: Bueno para reducir bias, eficaz con weak learners

### 2. Random Forest

#### Principio de Funcionamiento
- **Tipo**: Bagging con √°rboles de decisi√≥n
- **M√©todo de Fusi√≥n**: Votaci√≥n por mayor√≠a
- **Dependencia**: Independiente (entrenamiento paralelo)
- **Entrenamiento**: Bootstrap sampling + random feature selection

#### Caracter√≠sticas T√©cnicas
```python
# Hiperpar√°metros clave
n_estimators: N√∫mero de √°rboles (100 ‚Üí 1600 optimizado)
max_depth: Profundidad m√°xima de √°rboles
min_samples_split: M√≠nimo de muestras para divisi√≥n
max_features: N√∫mero de caracter√≠sticas por divisi√≥n
```

#### Rendimiento en Exoplanetas
- **Accuracy inicial**: 82.25%
- **Accuracy optimizada**: 82.64% (+0.39%)
- **Fortalezas**: Robusto, f√°cil implementaci√≥n, interpretable
- **Aplicaci√≥n**: Uno de los ensembles m√°s utilizados en astronom√≠a

### 3. Stacking (Stacked Generalization)

#### Principio de Funcionamiento
- **Tipo**: Meta-learning con m√∫ltiples niveles
- **M√©todo de Fusi√≥n**: Meta-modelo entrenado
- **Dependencia**: Jer√°rquica (meta-modelo aprende de base learners)
- **Entrenamiento**: Dos fases - base learners y meta-learner

#### Arquitectura
```
Nivel 1: Base Learners (ej. Random Forest, Gradient Boosting)
          ‚Üì
Nivel 2: Meta-Learner (aprende a combinar predicciones del Nivel 1)
```

#### Rendimiento en Exoplanetas
- **Accuracy inicial**: 82.72% (mejor inicial)
- **Accuracy optimizada**: 83.03%
- **Mejor combinaci√≥n**: LGBM + Gradient Boosting = 83.08%
- **Fortalezas**: 
  - Mejor rendimiento global
  - Capacidad de aprender combinaciones √≥ptimas
  - Flexibilidad en la elecci√≥n de algoritmos base

#### Configuraciones Evaluadas
| Base Learners | Accuracy | Observaciones |
|---------------|----------|---------------|
| Random Forest + Gradient Boosting | 83.03% | Configuraci√≥n est√°ndar |
| LGBM + Gradient Boosting | 83.08% | Mejor resultado |
| M√∫ltiples combinaciones | Variable | Exploraci√≥n sistem√°tica |

### 4. Random Subspace Method

#### Principio de Funcionamiento
- **Tipo**: Feature bagging
- **M√©todo de Fusi√≥n**: Votaci√≥n por mayor√≠a
- **Dependencia**: Independiente
- **Entrenamiento**: Selecci√≥n aleatoria de subconjuntos de caracter√≠sticas

#### Caracter√≠sticas T√©cnicas
```python
# Hiperpar√°metros clave
n_estimators: N√∫mero de algoritmos base
max_features: Fracci√≥n de caracter√≠sticas por subespacio
base_estimator: Algoritmo base (por defecto: Decision Tree)
```

#### Rendimiento en Exoplanetas
- **Accuracy inicial**: ~80.8%
- **Accuracy optimizada**: 81.91% (+1.1%)
- **Fortalezas**: Efectivo con alta dimensionalidad, reduce overfitting
- **Limitaciones**: No alcanz√≥ el 82% incluso optimizado

### 5. Extremely Randomized Trees (Extra Trees)

#### Principio de Funcionamiento
- **Tipo**: Bagging con randomizaci√≥n extrema
- **M√©todo de Fusi√≥n**: Votaci√≥n por mayor√≠a
- **Dependencia**: Independiente
- **Entrenamiento**: Randomizaci√≥n en selecci√≥n de splits y caracter√≠sticas

#### Diferencias con Random Forest
- **Splits aleatorios**: No busca el mejor split, usa splits aleatorios
- **Todo el dataset**: Usa todo el dataset (no bootstrap sampling)
- **Mayor randomizaci√≥n**: Reduce variance pero puede aumentar bias

#### Rendimiento en Exoplanetas
- **Accuracy inicial**: 82.06%
- **Accuracy optimizada**: 82.36% (+0.30%)
- **Caracter√≠sticas**: Mejora menor debido a la naturaleza aleatoria
- **Ventajas**: M√°s r√°pido que Random Forest, menos propenso a overfitting

## üìä An√°lisis Comparativo de Resultados

### Resumen de Performance
| Algoritmo | Accuracy Inicial | Accuracy Optimizada | Mejora | Ranking |
|-----------|------------------|---------------------|--------|---------|
| **Stacking** | 82.72% | **83.08%** | +0.36% | ü•á 1¬∞ |
| AdaBoost | 81.37% | 82.52% | +1.15% | ü•à 2¬∞ |
| Random Forest | 82.25% | 82.64% | +0.39% | ü•â 3¬∞ |
| Extra Trees | 82.06% | 82.36% | +0.30% | 4¬∞ |
| Random Subspace | ~80.8% | 81.91% | +1.10% | 5¬∞ |

### M√©tricas Detalladas (Stacking - Mejor Modelo)
```
Accuracy:    83.08%
Precision:   >80%
Recall:      >80%
F1-Score:    >82%
Specificity: >80%
```

## üîß Optimizaci√≥n de Hiperpar√°metros

### Metodolog√≠a de Tuning
1. **Grid Search**: B√∫squeda exhaustiva en espacio de par√°metros
2. **Iteraciones**: 100 combinaciones por algoritmo
3. **Validaci√≥n**: Cross-validation para evitar overfitting
4. **M√©tricas**: Accuracy como criterio principal de optimizaci√≥n

### Hiperpar√°metros Cr√≠ticos por Algoritmo

#### AdaBoost
- `n_estimators`: 50 ‚Üí Optimizado
- `learning_rate`: 1.0 ‚Üí Optimizado
- **Impacto**: +1.15% accuracy

#### Random Forest
- `n_estimators`: 100 ‚Üí 1600
- `max_depth`: Auto ‚Üí Optimizado
- **Impacto**: +0.39% accuracy

#### Stacking
- Base learners: Configuraci√≥n espec√≠fica
- Meta-learner: Optimizaci√≥n individual
- **Impacto**: +0.36% accuracy

## üéØ Aplicaci√≥n Espec√≠fica a Exoplanetas

### Ventajas de Ensemble en Astronom√≠a

#### Manejo de Ruido
- M√∫ltiples algoritmos compensan diferentes tipos de ruido
- Reducci√≥n de falsos positivos por consenso
- Mayor robustez ante artefactos instrumentales

#### Generalizaci√≥n
- Mejor performance en diferentes tipos de estrellas
- Adaptabilidad a diferentes misiones (Kepler, TESS, K2)
- Menor dependencia de caracter√≠sticas espec√≠ficas

#### Interpretabilidad Mejorada
- An√°lisis de consenso entre algoritmos
- Identificaci√≥n de caracter√≠sticas m√°s importantes
- Confianza en predicciones basada en acuerdo

### Desaf√≠os Espec√≠ficos

#### Computational Cost
- Mayor tiempo de entrenamiento e inferencia
- Necesidad de recursos computacionales superiores
- Balance entre performance y eficiencia

#### Complexity Management
- M√∫ltiples hiperpar√°metros por algoritmo base
- Riesgo de overfitting en meta-modelos
- Dificultad en debugging y troubleshooting

## üöÄ Mejores Pr√°cticas para Implementaci√≥n

### Selecci√≥n de Algoritmos Base
1. **Diversidad**: Combinar algoritmos con diferentes biases
2. **Complementariedad**: Algoritmos que cometan errores diferentes
3. **Performance Individual**: Algoritmos base con rendimiento razonable

### Estrategias de Combinaci√≥n
1. **Voting**: Simple majority o weighted voting
2. **Stacking**: Meta-learner para combinaci√≥n √≥ptima
3. **Blending**: Combinaci√≥n lineal con pesos optimizados

### Validaci√≥n y Testing
1. **Cross-Validation**: K-fold para robustez
2. **Holdout Sets**: Validaci√≥n en datos no vistos
3. **Temporal Splits**: Especialmente importante para series temporales

## üìà Futuras Direcciones

### Ensemble Avanzados
- **Deep Ensemble**: Combinaci√≥n de redes neuronales
- **Bayesian Ensemble**: Incorporaci√≥n de incertidumbre
- **Dynamic Ensemble**: Selecci√≥n adaptativa de modelos

### Optimizaci√≥n Autom√°tica
- **AutoML**: Selecci√≥n autom√°tica de algoritmos y par√°metros
- **Neural Architecture Search**: Para componentes deep learning
- **Multi-objective Optimization**: Balance accuracy-interpretability-efficiency

### Aplicaciones Espec√≠ficas
- **Real-time Processing**: Para datos de TESS en streaming
- **Multi-mission Integration**: Combinaci√≥n de datos Kepler/K2/TESS
- **Rare Event Detection**: Optimizaci√≥n para eventos poco frecuentes

---

**Anterior**: [Fundamentos Te√≥ricos](./theoretical-foundations.md) | **Siguiente**: [Metodolog√≠a de Implementaci√≥n](./implementation-methodology.md)