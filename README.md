<<<<<<< HEAD
# AI for Exoplanets
=======
# ExoData
---
Team: Planetaxies

A webapp focused on prossessing big amounts of information taken by spacial telescopes to filtrate the ones that doesn't count with the caracteristics of an exoplanet.

## Map of Contents
   1- [About the project](#about-the-project)  
   2- [Introduction](#introduction)
   3- Members of the team
   4- 
   
---
## About the project
The astronomers get a higher workload, every year the telescopes (TESS) send back to earth the information of spacial objects that its system considers its a exolpanet, offcourse it can be a false positive, this is the reason why astronomers are hired to prossess this information in order to check what objects have the caracteristics to be indentified as an exoplanet.

In case it doesn't count with the parameters to be an exoplanet it is cataloged as a false positive.

This is what we take as an oportunity, we made system that take the information that has been already prossessed by the astronomers and train a machine that is capable to read the information and learn what are the parameters that can be indentified as an exoplanet.

---
## Introduction
This system uses a predefined API developed by NASA (Transit and Ephemeris Service) that use the data

---
##


# ğŸš€ Exoplanet Detection AI
## NASA Space Apps Challenge 2025
>>>>>>> dbd11381613ae3f16bc45abdab9646e10363d330

## Description

Artificial Intelligence system for exoplanet detection using ensemble learning algorithms with data from NASA's Kepler, TESS, and K2 missions. The project implements a Stacking ensemble model that achieves 83.08% accuracy in the classification of celestial objects.

**Team: Planetaxies** - A web application focused on processing large amounts of information captured by space telescopes to filter objects that don't have the characteristics of an exoplanet, reducing the workload of astronomers in manual verification of candidates.

---

## ğŸ“Š Project Status and Branches

### Current Status
âœ… **Stable Production Version**: Functional system with trained model and API ready for use.

### Branch Structure

- **`main`**: Main branch with stable and tested code. Contains the functional version of the project with the implemented Stacking ensemble model.
- **`dev`**: Active development branch where new features are integrated before merging to `main`.
- **`feature/*`**: Specific branches for developing individual new features.

**Workflow:**
```
feature/* â†’ dev â†’ main
```

### Project Roadmap

- [x] Collect initial datasets (KOI, TOI, K2)
- [x] Define ML baseline (Random Forest / XGBoost)
- [x] Implement light curve preprocessing
- [x] Build API with FastAPI
- [ ] Connect web interface (React Frontend)

---

## ğŸš€ Installation and Setup

### Prerequisites

- **Python 3.8+** (Python 3.9 or higher recommended)
- **pip** for package management
- **Git** to clone the repository
- **Virtual environment** (venv or conda recommended)

### Quick Start

```bash
# Run the interactive setup script
python quick_start.py
```

### Manual Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/Itzel921/IA-para-exoplanetas.git
cd IA-para-exoplanetas
```

#### 2. Create and Activate Virtual Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate on Linux/Mac
source .venv/bin/activate

# Activate on Windows
.venv\Scripts\activate
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Configure Jupyter Notebook (Optional)

```bash
pip install jupyter ipykernel
python -m ipykernel install --user --name exoplanet-detection
```

---

## ğŸ’» Running the Project

### Train the Model

```bash
python train_models.py
```

This script runs the complete pipeline:
- Load and preprocess data (KOI, TOI, K2)
- Astronomical feature engineering
- Training of base models and meta-learner
- Evaluation and model saving

### Start the API Server

```bash
python -m uvicorn src.api.main:app --reload
```

Or for production:

```bash
python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

### Run Interactive Notebook

```bash
jupyter notebook exoplanet_detection_notebook.ipynb
```

### Make Predictions

#### REST API - Single Prediction

```python
import requests

response = requests.post("http://localhost:8000/api/predict", json={
    "period": 365.25,
    "planet_radius": 1.0,
    "stellar_radius": 1.0,
    "stellar_temperature": 5778,
    "equilibrium_temperature": 288
})

result = response.json()
print(f"Prediction: {result['prediction']}")  # 1=CONFIRMED, 0=FALSE_POSITIVE
print(f"Probability: {result['probability']:.3f}")
print(f"Confidence: {result['confidence']}")  # HIGH/MEDIUM/LOW
```

#### REST API - Batch Prediction

```bash
# POST /api/batch-predict with CSV file
curl -X POST "http://localhost:8000/api/batch-predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@candidates.csv"
```

### Available Endpoints

- **POST** `/api/predict` - Single exoplanet prediction
- **POST** `/api/batch-predict` - Batch predictions from CSV
- **GET** `/api/model-info` - Model metadata and performance metrics
- **WebSocket** `/ws/batch-progress` - Real-time batch processing progress

### Testing

```bash
# Run unit tests (when implemented)
pytest tests/

# Type checking
mypy src/

# Code formatting
black src/
```

---

## ğŸ—ï¸ Architecture and Technologies

### Technology Stack

#### Backend and API
- **FastAPI**: Modern, high-performance web framework
- **Uvicorn**: ASGI server for production
- **Pydantic**: Data validation and settings

#### Machine Learning
- **Scikit-learn**: ML algorithms and pipeline
- **LightGBM**: High-performance gradient boosting
- **Imbalanced-learn**: Class imbalance handling
- **Joblib**: Model serialization

#### Data Processing
- **Pandas**: Data manipulation and analysis
- **NumPy**: Numerical operations
- **SciPy**: Advanced scientific functions

#### Visualization
- **Matplotlib**: Static plots
- **Seaborn**: Statistical visualizations
- **Plotly**: Interactive graphics

#### Development Tools
- **Jupyter**: Interactive notebooks
- **pytest**: Testing framework
- **mypy**: Static type checking
- **black**: Automatic code formatting

### Ensemble Model Architecture

The system implements **Stacking Ensemble Learning** with two levels:

```
Prediction Pipeline:
Raw Data (KOI/TOI/K2) â†’ Preprocessing â†’ Feature Engineering â†’ Ensemble Models â†’ FastAPI â†’ React Frontend

Model Architecture:
Base Models (Level-0):
â”œâ”€â”€ Random Forest (1600 estimators)
â”œâ”€â”€ AdaBoost (200 estimators)
â”œâ”€â”€ Extra Trees (1000 estimators)
â””â”€â”€ LightGBM (500 estimators)
    â†“
Meta-Model (Level-1):
â””â”€â”€ LightGBM Meta-Learner
```

### Performance Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Accuracy** | 83.08% | Overall classification performance |
| **Precision** | 81.42% | Reliability (fraction of detections that are real planets) |
| **Recall** | 82.76% | Completeness (fraction of real planets detected) |
| **AUC-ROC** | 91.56% | Excellent discrimination capability |

**Practical Interpretation:**
- âœ… **Completeness**: 82.76% of real planets are detected
- âœ… **Reliability**: 81.42% of detections are confirmed as planets
- âš ï¸ **False Discovery Rate**: 18.58% (acceptable for follow-up observations)
- âš ï¸ **Missed Planet Rate**: 17.24% (room for improvement)

### Directory Structure

```
IA-para-exoplanetas/
â”‚
â”œâ”€â”€ ğŸ quick_start.py                    # Interactive setup script
â”œâ”€â”€ ğŸ¤– train_models.py                   # Main training pipeline
â”œâ”€â”€ ğŸ““ exoplanet_detection_notebook.ipynb # Experimentation notebook
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Project dependencies
â”œâ”€â”€ âš™ï¸ pyproject.toml                    # Project configuration
â”œâ”€â”€ ğŸ“œ LICENSE                           # MIT License
â”œâ”€â”€ ğŸ“– README.md                         # This file
â”‚
â”œâ”€â”€ ğŸ“ src/                              # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ¤– models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ensemble_algorithms.py       # Stacking & Random Subspace
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py               # NASA data loading and preprocessing
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸŒ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py                      # FastAPI application
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ”§ utils.py                      # Utilities and validation
â”‚
â”œâ”€â”€ ğŸ“ data/                             # NASA datasets (cached)
â”‚   â”œâ”€â”€ koi_data.csv                     # Kepler Objects of Interest
â”‚   â”œâ”€â”€ toi_data.csv                     # TESS Objects of Interest
â”‚   â””â”€â”€ k2_data.csv                      # K2 Mission data
â”‚
â”œâ”€â”€ ğŸ“ models/                           # Trained model artifacts
â”‚   â”œâ”€â”€ stacking_ensemble.pkl            # Main model
â”‚   â”œâ”€â”€ random_forest.pkl                # RF base model
â”‚   â”œâ”€â”€ adaboost.pkl                     # AdaBoost base model
â”‚   â”œâ”€â”€ extra_trees.pkl                  # ET base model
â”‚   â””â”€â”€ lightgbm.pkl                     # LGBM base model
â”‚
â”œâ”€â”€ ğŸ“ outputs/                          # Results, plots, and reports
â”‚   â”œâ”€â”€ plots/                           # Generated visualizations
â”‚   â”œâ”€â”€ reports/                         # Evaluation reports
â”‚   â””â”€â”€ predictions/                     # Saved predictions
â”‚
â””â”€â”€ ğŸ“ docs/                             # Documentation and research papers
    â””â”€â”€ research_papers.pdf              # Scientific reference articles
```

### Datasets Used

The project works with three main datasets from NASA missions:

1. **KOI (Kepler Objects of Interest)**
   - 9,654 objects Ã— 50+ features
   - Period: 2009-2017
   - Source: Kepler Mission

2. **TOI (TESS Objects of Interest)**
   - 6,000+ objects (continuously updated)
   - Period: 2018-present
   - Source: TESS Mission

3. **K2 (Kepler Second Light)**
   - Multiple campaigns (C0-C19)
   - Diverse stellar fields
   - Source: K2 Mission

### Feature Engineering

The system implements 15+ derived features with astronomical significance:

#### Orbital Parameters
- Orbital period
- Planet radius
- Stellar radius

#### Transit Characteristics
- Transit depth
- Transit duration
- Signal-to-noise ratio

#### Stellar Properties
- Effective temperature
- Stellar mass
- Metallicity
- Stellar age

#### Derived Features
```python
# Examples of calculated features
planet_star_radius_ratio = koi_prad / koi_srad
equilibrium_temp_ratio = koi_teq / koi_steff
transit_depth_expected = (koi_prad / koi_srad) ** 2 * 1e6  # in ppm
in_habitable_zone = (200 <= koi_teq <= 320)  # Earth-like temperatures
```

### Preprocessing Pipeline

1. **Missing Value Imputation**: Domain-specific strategies
   - Stellar parameters: Median imputation
   - Planetary parameters: Conditional median by disposition

2. **Outlier Handling**: Winsorization (1%-99% percentiles)

3. **Feature Scaling**: RobustScaler (outlier-resistant)

4. **Feature Engineering**: 15+ derived astronomical features

5. **Hyperparameter Tuning**: Grid search with 5-fold cross-validation

6. **Class Imbalance**: 
   - Stratified sampling
   - SMOTE (optional)

7. **Feature Selection**: Recursive feature elimination

8. **Ensemble Diversity**: Different algorithms with varied hyperparameters

---

## ğŸ³ Docker Deployment

### Build the Image

```bash
docker build -t exoplanet-detection-ai .
```

### Run the Container

```bash
docker run -p 8000:8000 exoplanet-detection-ai
```

### Production Deployment Architecture

- **Backend**: FastAPI + Gunicorn + nginx
- **Database**: PostgreSQL for logging
- **Cache**: Redis for frequent results
- **Monitoring**: Prometheus + Grafana
- **Scaling**: Kubernetes with horizontal pod autoscaling

---

## ğŸ“š Scientific Foundation

This project is based on peer-reviewed scientific research:

### Main Paper
**"Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Detection"** (Electronics 2024)
- Stacking ensemble achieves 83.08% accuracy
- Random Forest: 82.64%, AdaBoost: 82.52%
- Comprehensive comparison of 5 ensemble methods

### Additional References
- **"Exoplanet Detection Using Machine Learning"** (MNRAS 2022)
  - Feature importance analysis for astronomical parameters
  - Time-series analysis with TSFRESH (789 features)

- **NASA Exoplanet Archive Methodology**
  - Data validation and vetting procedures
  - Statistical significance thresholds

---

## ğŸ¤ Contributing

### Contribution Workflow

1. **Fork the Repository**
```bash
git clone https://github.com/your-username/IA-para-exoplanetas.git
cd IA-para-exoplanetas
```

2. **Create Feature Branch from `dev`**
```bash
git checkout dev
git pull origin dev
git checkout -b feature/descriptive-name
```

3. **Develop Your Feature**
   - Write code following PEP 8 style guide
   - Add docstrings to all functions
   - Include unit tests for new features
   - Update documentation as needed

4. **Commit Changes**
```bash
git add .
git commit -m "feat: clear description of your change"
```

**Commit convention:**
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation changes
- `refactor:` Code refactoring
- `test:` Test addition or modification
- `style:` Formatting changes
- `perf:` Performance improvements

5. **Push and Pull Request**
```bash
git push origin feature/descriptive-name
```
- Open a Pull Request to the **`dev`** branch
- Clearly describe the changes made
- Reference related issues if applicable
- Wait for team review

### Style Guide

- Follow **PEP 8** for Python code
- Maximum line length: 88 characters (Black compatible)
- Use **type hints** in all functions
- Document with **docstrings** (Google format)
- Descriptive names for variables and functions

### Code Quality Tools

```bash
# Automatic formatting
black src/

# Style checking
flake8 src/

# Type checking
mypy src/
```

---

## ğŸ“„ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for more details.

---

## ğŸŒŸ Acknowledgments

- **NASA** for providing open access to Kepler, TESS, and K2 data
- **NASA Exoplanet Archive** for maintaining high-quality databases
- **Kepler/K2 and TESS Missions** for groundbreaking observations
- **Space Apps Challenge 2025** for the opportunity to contribute to space science
- **Scientific community** for open-access publications and methodologies

---

## ğŸ“§ Contact

**NASA Space Apps Challenge 2025 Team - Planetaxies**

- ğŸ“§ Email: [team@example.com](mailto:team@example.com)
- ğŸ™ GitHub: [Itzel921/IA-para-exoplanetas](https://github.com/Itzel921/IA-para-exoplanetas)
- ğŸŒ Website: [Coming Soon]

---

## ğŸ”— References and Resources

### APIs and Data
- [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/)
- [TESS Mission](https://tess.mit.edu/)
- [Kepler Mission](https://www.nasa.gov/mission_pages/kepler/overview/index.html)

### Technical Documentation
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)

### Research Papers
Available in the `docs/` folder of the repository.

---

â­ **If you find this project useful, give us a star!** â­