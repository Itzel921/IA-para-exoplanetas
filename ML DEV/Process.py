"""
Sistema Principal de Procesamiento - Exoplanetas ML
Integra carga de datos, entrenamiento y predicciÃ³n
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys

# Importaciones necesarias para que joblib pueda cargar los modelos correctamente
import model_imports  # Esto asegura que todas las clases estÃ©n disponibles

def show_menu():
    """Muestra el menÃº principal del sistema"""
    print("\n" + "="*60)
    print("ğŸŒŸ SISTEMA DE DETECCIÃ“N DE EXOPLANETAS")
    print("    NASA Space Apps Challenge 2025")
    print("="*60)
    print("\nğŸ“‹ OPCIONES DISPONIBLES:")
    print("1. ğŸ“Š Cargar y analizar datasets (KOI, TOI, K2)")
    print("2. ğŸ¯ Entrenar modelo ensemble (Stacking + RF + AdaBoost)")
    print("3. âš¡ Entrenar modelo simplificado (RÃPIDO - Random Forest)")
    print("4. ğŸ”® Predecir exoplanetas en nuevo dataset")
    print("5. ğŸ“ Procesar todos los archivos en new_datasets")
    print("6. ğŸ“ˆ AnÃ¡lisis exploratorio completo")
    print("7. â“ Ayuda y documentaciÃ³n")
    print("8. ğŸšª Salir")
    print("\n" + "-"*60)

def option_1_load_datasets():
    """OpciÃ³n 1: Cargar y analizar datasets"""
    print("\nğŸ”„ Ejecutando anÃ¡lisis de datasets...")
    
    try:
        from Clasification import DataLoader
        
        # Configurar paths
        current_dir = Path(__file__).parent
        project_root = current_dir.parent
        
        # Cargar y mostrar informaciÃ³n de datasets
        loader = DataLoader(project_root)
        datasets = loader.load_all_datasets()
        
        if len(datasets) > 0:
            print(f"\nğŸ“Š RESUMEN DE DATASETS CARGADOS:")
            print("="*50)
            
            total_rows = 0
            for name, df in datasets.items():
                print(f"\nğŸ“ Dataset: {name}")
                print(f"   ğŸ“ Dimensiones: {df.shape[0]:,} Ã— {df.shape[1]}")
                print(f"   ğŸ“‹ Columnas principales: {list(df.columns[:5])}")
                total_rows += df.shape[0]
                
                # Mostrar distribuciÃ³n de clases si existe columna objetivo
                target_cols = ['koi_disposition', 'tfopwg_disp', 'archive_disp']
                for col in target_cols:
                    if col in df.columns:
                        print(f"   ğŸ¯ DistribuciÃ³n {col}:")
                        value_counts = df[col].value_counts()
                        for val, count in value_counts.items():
                            percentage = (count / len(df)) * 100
                            print(f"      â€¢ {val}: {count:,} ({percentage:.1f}%)")
                        break
            
            print(f"\nğŸ“Š TOTAL COMBINADO: {total_rows:,} objetos astronÃ³micos")
            print("âœ… AnÃ¡lisis de datasets completado!")
            
        else:
            print("âŒ No se pudieron cargar los datasets")
            print("   Verifica que los archivos CSV estÃ©n en data/datasets/")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis: {e}")
        import traceback
        traceback.print_exc()

def option_2_train_model():
    """OpciÃ³n 2: Entrenar modelo ensemble"""
    print("\nğŸ¯ Iniciando entrenamiento del modelo...")
    print("â³ Este proceso puede tomar varios minutos...")
    
    try:
        # Importar las clases necesarias
        from train_ensemble import ExoplanetMLSystem
        from Clasification import DataLoader
        
        # Configurar paths
        current_dir = Path(__file__).parent
        project_root = current_dir.parent
        
        print("ğŸ“‚ Cargando datasets de NASA (KOI, TOI, K2)...")
        
        # Cargar datasets
        loader = DataLoader(project_root)
        datasets = loader.load_all_datasets()
        
        if len(datasets) > 0:
            print(f"âœ… {len(datasets)} datasets cargados exitosamente!")
            
            # Inicializar y entrenar sistema
            ml_system = ExoplanetMLSystem(project_root)
            model_info = ml_system.train_system(datasets)
            
            print("âœ… Entrenamiento completado!")
            print(f"ğŸ¯ Accuracy alcanzado: {model_info['accuracy']:.4f}")
            print("ğŸš€ Sistema listo para predicciones!")
            
        else:
            print("âŒ No se pudieron cargar los datasets para entrenamiento")
            print("   Verifica que los archivos CSV estÃ©n en data/datasets/")
        
    except Exception as e:
        print(f"âŒ Error en entrenamiento: {e}")
        import traceback
        traceback.print_exc()

def option_3_simple_train():
    """OpciÃ³n 3: Entrenar modelo simplificado (RÃPIDO)"""
    print("\nâš¡ Iniciando entrenamiento simplificado...")
    print("ğŸš€ Este proceso es mÃ¡s rÃ¡pido y usa menos recursos")
    print("ğŸ¯ Usando Random Forest con caracterÃ­sticas astronÃ³micas optimizadas")
    
    try:
        # Importar el entrenador simplificado
        import simple_retrain
        
        print("ğŸ“‚ Ejecutando reentrenamiento simplificado...")
        model_info = simple_retrain.main()
        
        if model_info:
            print("âœ… Â¡Entrenamiento simplificado completado exitosamente!")
            print(f"ğŸ¯ Accuracy: {model_info['accuracy']:.4f} ({model_info['accuracy']*100:.1f}%)")
            print(f"ğŸ”¬ CaracterÃ­sticas: {model_info['n_features']}")
            print(f"ğŸ“Š Precision: {model_info['precision']:.3f}")
            print(f"ğŸ“Š Recall: {model_info['recall']:.3f}")
            print("ğŸš€ El modelo estÃ¡ listo para predicciones!")
        else:
            print("âŒ Error en el entrenamiento simplificado")
        
    except Exception as e:
        print(f"âŒ Error en entrenamiento simplificado: {e}")
        import traceback
        traceback.print_exc()

def option_4_predict_single():
    """OpciÃ³n 4: Predecir en dataset especÃ­fico usando predictor corregido"""
    new_datasets_path = Path(__file__).parent.parent / "data" / "new_datasets"
    
    print(f"\nğŸ“ Archivos disponibles en new_datasets:")
    csv_files = list(new_datasets_path.glob("*.csv"))
    
    if not csv_files:
        print("âŒ No hay archivos CSV en la carpeta new_datasets")
        print(f"   Coloca archivos en: {new_datasets_path}")
        return
    
    for i, file in enumerate(csv_files, 1):
        print(f"   {i}. {file.name}")
    
    try:
        choice = int(input("\nğŸ”¢ Selecciona el nÃºmero del archivo: "))
        if 1 <= choice <= len(csv_files):
            filename = csv_files[choice - 1].name
            
            print(f"\nğŸ”® Usando predictor corregido compatible con modelo actual...")
            
            # Usar el predictor corregido
            from simple_predictor_fixed import SimplePredictorFixed
            predictor = SimplePredictorFixed(Path(__file__).parent.parent)
            
            if predictor.load_model():
                predictor.process_file(filename)
            else:
                print("âŒ Primero debes entrenar un modelo")
        else:
            print("âŒ SelecciÃ³n invÃ¡lida")
            
    except ValueError:
        print("âŒ Por favor ingresa un nÃºmero vÃ¡lido")
    except Exception as e:
        print(f"âŒ Error: {e}")

def option_5_predict_all():
    """OpciÃ³n 5: Procesar todos los archivos usando predictor corregido"""
    print("\nğŸ”„ Procesando todos los archivos en new_datasets...")
    
    try:
        print("ğŸ”® Usando predictor corregido compatible con modelo actual...")
        
        from simple_predictor_fixed import SimplePredictorFixed
        predictor = SimplePredictorFixed(Path(__file__).parent.parent)
        
        if predictor.load_model():
            predictor.process_all_new_datasets()
        else:
            print("âŒ Primero debes entrenar un modelo")
            
    except Exception as e:
        print(f"âŒ Error: {e}")

def option_6_full_analysis():
    """OpciÃ³n 6: AnÃ¡lisis exploratorio completo con visualizaciones avanzadas"""
    print("\nğŸ“Š Ejecutando anÃ¡lisis exploratorio completo...")
    
    try:
        from Clasification import DataLoader
        from advanced_visualization import ExoplanetVisualizer
        
        current_dir = Path(__file__).parent
        project_root = current_dir.parent
        
        # Cargar datasets NASA
        print("ğŸ“ Cargando datasets NASA...")
        loader = DataLoader(project_root)
        nasa_datasets = loader.load_all_datasets()
        
        # Cargar new_datasets si existen
        print("ï¿½ Cargando new_datasets...")
        new_datasets = {}
        new_datasets_path = project_root / "data" / "new_datasets"
        
        if new_datasets_path.exists():
            csv_files = list(new_datasets_path.glob("*.csv"))
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file, comment='#', sep=',', engine='python')
                    file_name = csv_file.stem
                    new_datasets[file_name] = df
                    print(f"   âœ… {file_name}: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
                except Exception as e:
                    print(f"   âš ï¸ Error cargando {csv_file.name}: {e}")
        
        # Crear visualizador
        visualizer = ExoplanetVisualizer(project_root)
        
        # Generar todas las visualizaciones
        generated_files = visualizer.generate_complete_analysis(nasa_datasets, new_datasets)
        
        # Mostrar resumen estadÃ­stico
        print(f"\nğŸ“ˆ RESUMEN ESTADÃSTICO")
        print("="*50)
        
        print("ğŸ“Š Datasets NASA:")
        for name, df in nasa_datasets.items():
            analysis = loader.analyze_dataset(df, name)
            print(f"   â€¢ {name}: {df.shape[0]:,} objetos, {df.shape[1]} caracterÃ­sticas")
            if analysis.get('target_column'):
                target_col = analysis['target_column']
                if target_col in df.columns:
                    class_dist = df[target_col].value_counts()
                    print(f"     - Clases: {dict(class_dist)}")
        
        if new_datasets:
            print("\nğŸ“ New Datasets:")
            for name, df in new_datasets.items():
                print(f"   â€¢ {name}: {df.shape[0]:,} objetos, {df.shape[1]} caracterÃ­sticas")
        
        print(f"\nğŸ¨ Visualizaciones generadas: {len(generated_files)}")
        print("   ğŸ“‚ Ubicaciones:")
        print("      â€¢ Charts individuales: exoPlanet_results/charts/")
        print("      â€¢ Charts comparativos: exoPlanet_results/comparative_charts/")
        
        print("\nâœ… AnÃ¡lisis exploratorio completo finalizado!")
        
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis: {e}")
        import traceback
        traceback.print_exc()

def option_7_help():
    """OpciÃ³n 7: Ayuda y documentaciÃ³n"""
    print("\nğŸ“š DOCUMENTACIÃ“N DEL SISTEMA")
    print("="*50)
    
    print("""
ğŸ¯ OBJETIVO:
   Detectar exoplanetas usando ensemble learning con 83.08% de accuracy

ğŸ“Š DATASETS SOPORTADOS:
   â€¢ KOI (Kepler Objects of Interest): ~9,600 objetos
   â€¢ TOI (TESS Objects of Interest): ~6,000 objetos  
   â€¢ K2 Planets and Candidates: MÃºltiples campaÃ±as

ğŸ§  ALGORITMOS DE ML:
   â€¢ Stacking Ensemble (mejor: 83.08% accuracy)
   â€¢ Random Forest (82.64%)
   â€¢ AdaBoost (82.52%)
   â€¢ Gradient Boosting + LightGBM

ğŸ“ ESTRUCTURA DE CARPETAS:
   â€¢ data/datasets/: Datasets originales (KOI, TOI, K2)
   â€¢ data/new_datasets/: Nuevos archivos para predicciÃ³n
   â€¢ exoPlanet_results/: Resultados de predicciones
   â€¢ models/: Modelos entrenados guardados

ğŸš€ FLUJO DE TRABAJO:
   1. Analizar datasets existentes (opciÃ³n 1)
   2. Entrenar modelo ensemble (opciÃ³n 2) 
   3. Colocar nuevos CSV en data/new_datasets/
   4. Predecir exoplanetas (opciÃ³n 3 o 4)
   5. Revisar resultados en exoPlanet_results/

ğŸ“‹ FORMATO DE RESULTADOS:
   â€¢ CSV con columnas originales + predicciones ML
   â€¢ ML_Probability: Probabilidad de ser exoplaneta (0-1)
   â€¢ ML_Prediction: PredicciÃ³n binaria (1=exoplaneta, 0=no)
   â€¢ ML_Confidence: Nivel de confianza de la predicciÃ³n
   â€¢ ML_Classification: 'CONFIRMED' o 'NOT_CONFIRMED'

ğŸ”¬ BASE CIENTÃFICA:
   â€¢ Research papers: Electronics 2024, MNRAS 2022
   â€¢ Feature engineering astronÃ³mico especializado
   â€¢ ValidaciÃ³n cruzada estratificada para clases desbalanceadas
   """)

def main():
    """FunciÃ³n principal del sistema"""
    
    while True:
        show_menu()
        
        try:
            choice = input("ğŸ”¢ Selecciona una opciÃ³n (1-8): ").strip()
            
            if choice == '1':
                option_1_load_datasets()
            elif choice == '2':
                option_2_train_model()
            elif choice == '3':
                option_3_simple_train()
            elif choice == '4':
                option_4_predict_single()
            elif choice == '5':
                option_5_predict_all()
            elif choice == '6':
                option_6_full_analysis()
            elif choice == '7':
                option_7_help()
            elif choice == '8':
                print("\nğŸ‘‹ Â¡Gracias por usar el Sistema de DetecciÃ³n de Exoplanetas!")
                print("ğŸŒŸ NASA Space Apps Challenge 2025")
                break
            else:
                print("âŒ OpciÃ³n invÃ¡lida. Por favor selecciona 1-8.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Saliendo del sistema...")
            break
        except Exception as e:
            print(f"âŒ Error inesperado: {e}")
        
        input("\nâ¸ï¸  Presiona Enter para continuar...")

if __name__ == "__main__":
    main()
